% DOC CLASS
\documentclass[11pt]{article}

% ENCODING
\usepackage[utf8]{inputenc}
\usepackage[brazilian]{babel}

% OUTPUT
\usepackage[nottoc]{tocbibind}
\usepackage{hyperref}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage{makeidx}
\usepackage{float}
\usepackage{array}
\usepackage{boxedminipage}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{amsfonts}
\usepackage{setspace}
\usepackage{comment}
\usepackage[toc,xindy]{glossaries}

% SOURCE CODE
\usepackage{listings}
\usepackage{color}
\usepackage{xcolor}
\usepackage{caption}
\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{\colorbox{gray}{\parbox{\textwidth}{#1#2#3}}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white}

% MARGIN
\setlength{\oddsidemargin}{0.5cm} \setlength{\textwidth}{15cm}
\setlength{\topmargin}{-1.5cm} \setlength{\textheight}{22.3cm}%{24.7cm}
\setlength\parindent{0pt} % Removes all indentation from paragraphs
\renewcommand{\labelenumi}{\alph{enumi}.} % Make numbering in the enumerate environment by letter rather than number (e.g. section 6)

% GLOSSARIES
\makeglossaries
\newacronym{api}{API}{Application Programming Interface}
\newacronym{rfc}{RFC}{Request for Comments}
\newacronym{rpc}{RPC}{Remote Procedure Calls}

% DOCUMENT
\begin{document}

\title{Disciplina de Sistemas Distrbuídos [INF 2545] \\ Biblioteca RPC -
Trabalho 1}
\author{Rogério Carvalho Schneider}
\date{Abril 2014}
\maketitle

\begin{center}
\begin{tabular}{l r}
Data dos testes: & 14 de Abril de 2014 \\
Professora: & Noemi Rodriguez
\end{tabular}
\end{center}

\begin{abstract}
Relatório da implementação e testes realizados na biblioteca \textit{luarpc}
para a disciplina de Sistemas Distribuídos do Departamento de Informática da PUC-Rio.
A linguagem Lua foi utilizada na implementação da biblioteca.
\end{abstract}

\doublespacing

\section{Introdução}\label{sec:introduction}

Desenvolvemos uma biblioteca para auxílio a chamada remota de
procedimento, \gls{rpc}, com o objetivo de enfrentar e resolver alguns dos problemas
de comunicação de rede em sistemas distribuídos. A programação de servidor e
cliente \gls{rpc} também serviu de exercício na definição, entendimento e
implementação de um protocolo de comunicação.

A biblioteca consiste no arquivo \textit{luarpc.lua}, que depende da
definição de um arquivo de interface, normalmente chamado de
\textit{interface.lua}. A biblioteca deve poder ser reutilizada por diferentes
implementações de servidor e cliente, para tanto, um contrato foi firmado entre
os desenvolvedores (os alunos da disciplina) de maneira a seguir uma \gls{api}
comum a todas as implementações da biblioteca \textit{luarpc}. Da mesma forma,
foi necessário entrar em acordo quanto ao protocolo de comunicação de rede e de
codificação/decodificação de mensagens a ser utilizado. A implementação desta
biblioteca \gls{rpc} segue as linhas gerais definidas no enunciado do trabalho\cite{trab1}.

A \gls{api} utilizada foi aquela do enunciado do trabalho, com os métodos
\textit{luarpc.createServant}, \textit{luarpc.waitIncoming} e
\textit{luarpc.createProxy} com exatamente o mesmo número e tipo de parâmetros
sugeridos pelo texto original. O protocolo sofreu pequenas alterações,
principalmente no que diz respeito a forma de codificação e decodificação do
conteúdo das mensagens enviadas.

Durante a evolução da definição do protocolo, uma lista de discussão por
\textit{e-mail} for arranjada de forma que as propostas fossem
comentadas pelos participantes do consórcio que patrocinaria o desenvolvimento
da biblioteca. Uma \gls{rfc} foi definida na lista de discussão e após algumas
rodadas de comentários o consórcio chegou a um entendimento quanto
ao protocolo a ser implementado.

\section{Uma biblioteca RPC}\label{sec:rpc}

Uma boa especificação de uma biblioteca de auxílio a chamada remota de
procedimento funciona da seguinte maneira: A sua \gls{api} sugerida deve ser
clara e consistente, no sentido de que diferentes implementações possam se
comportar de maneira idêntica quando estiverem se comunicando com recursos
externos. Para clarificar, uma biblioteca deve manter um comportamento
consistente ao interagir com o arquivo de interface e ao receber chamadas de
criação e tratamento de \textit{servant} e de \textit{proxy} para procedimentos remotos.
A biblioteca deve,
portanto, fornecer um conjunto padronizado de métodos de criação e configuração
de servidores e clientes, e deve interpretar de maneira correta um arquivo de
interface escrito seguindo a \gls{api} especificada.

Na prática, a proposta de especificação e implementação consistente de uma
biblioteca \gls{rpc} espera que os usuários/programadores possam intercambiar
seus diferentes servidores e clientes, desde que todos sigam uma mesma definição
de interface. Uma vez de posse da interface, um cliente qualquer pode,
utilizando a biblioteca proposta \textit{luarpc}, fazer requisições a um
servidor qualquer, para tanto basta que ambos cliente e servidor respeitem e
implementem o correto tratamento do arquivo de interface.

\subsection{O protocolo}\label{subsec:proto}

Particularmente, a regra definida para o protocolo e codificação de mensagens
neste trabalho foi a seguinte:

\begin{itemize}
\item
Nomes de métodos chamados pelo cliente são enviados sem delimitadores;
\item
Parâmetros do tipo \textit{char} ou \textit{string} são enviados com delimitadores
\textit{""} envolvendo o texto transmitido;
\item
Parâmetros do tipo \textit{double} são enviados sem transformação.
\item
Parâmetros do tipo \textit{void} são transformados em \textit{nil} e são enviados
com delimitadores \textit{""} envolvendo o texto transmitido. Resulta no envio
de \textit{"nil"};
\end{itemize}

Ao transmitir conteúdo é necessário que ele seja serializado, codificando
conforme o seguinte acordo, no transmissor:

\begin{itemize}
\item
Usar sequência de escape para \textit{\textbackslash{}}, transformando em \textit{\textbackslash{}\textbackslash{}};
\item
Usar sequência de escape para \textit{\textbackslash{}n}, transformando em \textit{\textbackslash{}\textbackslash{}n};
\item
Usar sequência de escape para \textit{"}, transformando em \textit{\textbackslash{}"};
\item
O processo inverso, de decodificação, deve ser feito no receptor.
\end{itemize}

Os tipos válidos \textit{char}, \textit{string}, \textit{double} e
\textit{void} tem o seguinte protocolo de
codificação/decodificação:

\begin{itemize}
\item
\textit{char}: restrito a um caracter
codificação no transmissor: envolto em \textit{""}
exemplo: \textit{"a"}
decodificação no receptor: remove \textit{""}
exemplo: \textit{a}
\item
\textit{string}: sem restrição
codificação no transmissor: envolto em \textit{""}
exemplo: \textit{"abc"}
decodificação no receptor: remove \textit{""}
exemplo: \textit{abc}
\item
\textit{double}: apenas números inteiros ou de ponto flutuante
codificação no transmissor: não há
exemplo: \textit{3.1415}
decodificação no receptor: não há
exemplo: \textit{3.1415}
\item
\textit{void}: transformado em nil, envolto em \textit{""}
codificação no transmissor: nil e \textit{""}
exemplo: \textit{"nil"}
decodificação no receptor: remove \textit{""}
exemplo: \textit{nil}
\item
Todos os tipos devem ser enviados em apenas uma chamada de \textit{socket:send()}
e recebidos em apenas uma chamada \textit{socket:receive()}, desta maneira, o
correto escape de \textit{string} com quebras de linha (\textit{\textbackslash{}n}) é muito importante.
\end{itemize}

O papel do receptor é desfazer a codificação aplicada, seguindo a sequência
inversa de passos, de forma a obter valor e tipo originais transmitidos na
mensagem. Uma saída adotada por alguns desenvolvedores para fazer o escape
inverso de \textit{string}, por exemplo, foi o uso de uma chamada
\textit{return} no conteúdo recebido, o que faz com que alguns escapes sejam
decodificados transparentemente, evitando a necessidade de tratar manualmente,
por exemplo, a remoção de delimitadores \textit{""} no início e fim da linha recebida. Da
mesma forma as contra-barras de sequência de escape também são removidas
automaticamente. De forma contrária, como outras implementações sugeriram,
utilizar esse tipo de artifício pode facilitar a vida do programador mas ao mesmo
tempo introduz uma falha de segurança que permite que uma mensagem trocada
entre cliente e servidor, quando decodificada, tenha seu \textit{payload}
executado como código Lua, abrindo uma brecha para execução remota de código não
desejado. Para evitar este problema, foi utilizada a alternativa de tratamento
manual do conteúdo, fazendo uso de técnica de \textit{search and replace} dos
carateres codificados \textit{\textbackslash{}"}, \textit{\textbackslash{}\textbackslash{}n} e delimitadores \textit{""}. As funções
\textit{string.gsub()} e \textit{string.sub(2,-2)} foram utilizadas para
decodificar \textit{\textbackslash{}"} em \textit{"}, \textit{\textbackslash{}\textbackslash{}n} em \textit{\textbackslash{}n} e remover os
delimitadores \textit{""}.

Ao perceber um erro no lado do cliente ou do servidor, o protocolo deve enviar
uma mensagem iniciada por "\_\_\_ERRORPC:" contendo, possivelmente, a causa do
erro. Em alguns casos especiais de erro no modo de uso, a biblioteca deve tentar evitar
o envio da mensagem de erro e deve tentar corrigir o número e tipo de parâmetros chamados no
cliente ou respondidos pelo servidor. Para tanto, a biblioteca utiliza valores default como
alternativa à falta de parâmetros nas chamadas do cliente e nas respostas do
servidor. O objetivo é prover uma construção o mais limpa possível da sequência
de mensagens a trafegar no canal de comunicação de rede, tentando sempre respeitar o
protocolo definido quanto a tipos, quantidade, codificação e sequência de
parâmetros esperados no transporte entre cliente e servidor, ida e volta.

\section{Testes de performance realizados}\label{sec:perf}

Foram executadas baterias de teste segundo a sugestão do enunciado do trabalho.
Para cada configuração de cenário segue abaixo um parecer e algumas informações
adicionais.

Um cliente especial foi criado para a execução dos testes. Este cliente tem
capacidade de medir o tempo que leva para executar uma série de chamadas em
sequência e também consegue medir o quanto consumiu de tráfego de rede para a
série de chamadas. Em todas as baterias foram executadas 10000 (dez mil)
chamadas a cada método. Os métodos chamados no laço de teste também foram
especialmente implementados e escolhidos para terem diferentes comportamentos
quanto ao custo de tráfego de rede (mensagens pequenas, mensagens grandes) e
custo de processamento (tempo de CPU). Também foram realizadas medições isoladas
para determinar qual o custo de tempo imposto pela biblioteca \textit{luarpc} e
qual o custo imposto pela implementação presente no cliente e no servidor.

\subsection{Tamanho de string muito pequeno e muito grande}\label{subsec:stringsize}

Neste teste foi utilizado o método chamado \textit{min}, que recebe um string e
devolve apenas um double. Este perfil de teste demonstra o impacto do aumento
do tráfego de dados no desempenho da aplicação.

Como resultado obtivemos um total de 1120K bytes enviados e 1060K recebidos pelo
cliente com um tempo total de duração de 2 segundos para 10000 requisições. O
string enviado era mínimo no primeiro teste, apenas um byte.

No segundo teste, usando o mesmo método mas agora com string muito grande, com
osugerido no roteiro de testes do enuncido do trabalho, obtivemos um total de
104M bytes enviados e 1060K bytes recebidos pelo cliente com um tempo total de
duração de 21 segundos para 10000 requisições. O string enviado era grande,
continha 10k bytes.

\begin{lstlisting}[label={ifacemin},language=C,caption=Interface min]
    min = {
      resulttype = "double",
      args = {
        {direction = "in", type = "string"},
      },
    },
\end{lstlisting}

\subsection{Conexão persistente contra conexão sem reuso}\label{subsec:persist}

Dois outros testes interessantes sobre o custo da conexão do cliente com o
servidor foram realizados. O método utilizado foi o \textit{min} por oferecer
duas visões diferentes, uma delas com pouco tráfego de dados e outra com grande
tráfego de dados (e portanto com conexões que duram mais tempo, até que os dados
todos sejam trafegados de um lado para o outro).

O perfil mencionado no teste de string pequeno e grande foi realizado usando
conexão persistente e tinha duração de 2 segundos para string pequeno e 21
segundos para string grande. O mesmo perfil de teste aplicado ao servidor que fecha a conexão do cliente
assim que ele termina de ser atendido fez com que o tempo total de atendimento
do laço de 2 segundos pulasse a 4 segundos para o string pequeno. Para
o string grande não houve modificação no tempo, o que pode ser explicado pela
menor importância do tempo de conexão perto do tempo de tráfego de rede que
custa para o perfil de string grande. Para o perfil de string pequeno é possível
perceber que o tempo de conexão representa uma parte do tempo total da execução
do teste.

\subsection{Serializando e deserializando uma tabela grande}\label{subsec:serdeser}

Outro perfil executado foi o sugerido de serializar uma tabela com 100 doubles.
A serialização transforma uma tabela em um string e envia este string para o
servidor em uma chamada de tipo nativo simples, chamada aqui de \textit{tbl} e
que recebe um string e devolve um double. Para este teste foram usados dois
servidores, um que apenas responde "0" e que não fazer deserialização da tabela,
e outro que responde "1" e faz a deserialização da tabela.

Foi possível observar que neste perfil não houve muita diferença entre o tempo
do servidor que deserializa a tabela e o servidor que não trata da decodificação
da tabela.

Como resultado obtivemos um total de 21M bytes enviados e 1060K bytes recebidos pelo
cliente com um tempo total de duração de 8 segundos sem deserialização e 9
segundos com deserialização no lado do servidor para 10000 requisições.

\begin{lstlisting}[label={ifacetbl},language=C,caption=Interface tbl]
    tbl = {
      resulttype = "double",
      args = {
        {direction = "in", type = "string"},
      },
    },
\end{lstlisting}

Ainda sobre a tabela, medimos a execução isolada de serialização e
deserialização da tabela sem o envolvimento de cliente e servidor \gls{rpc}. As
chamadas em laço local levaram 4 segundos para serializar e 2 segundos para
deserializar a tabela com 100 doubles em 10000 iterações, totalizando 6 segundos
de tempo total de execução local.

\subsection{Diferente número de clientes para pool de conexões}\label{subsec:diffpool}

Um teste final foi executado configurando um servidor para atender a até três
clientes com conexão persistente simultânea. O \textit{pool} (a fila circular)
do servidor foi configurada com tamanho 3.

Em um primeiro perfil apenas um cliente se conectou ao servidor, sem gerar
concorrência com outros clientes. Neste caso o atendimento foi satisfatório para
o método \textit{foo}, levando apenas 2 segundos para executar 10000 operações
de soma de dois doubles e de devolução da resposta em conjunto com um string
pequeno.

\begin{lstlisting}[label={ifacefoo},language=C,caption=Interface foo]
    foo = {
      resulttype = "double",
      args = {
        {direction = "in", type = "double"},
        {direction = "in", type = "double"},
        {direction = "out", type = "string"},
      },
    },
\end{lstlisting}

Na segunda execução, com três clientes, a concorrência já causou impacto no
tempo de execução, mas mesmo assim todos os clientes ainda estavam podendo
manter as suas conexões abertas o tempo todo, sem necessidade de reconexão.
Neste perfil o tempo subiu para 7 segundos em cada cliente.

O último perfil sugerido, com 10 clientes para forçar a reconexão sequencial de
todos de tempos em tempos não pode ser executado até o final por um provável
erro de implementação da biblioteca. O consumo de memória, possivelmente devido
ao grande número de reconexões, impediu que o perfil completasse a execução
antes de travar o \textit{hardware} dos testes. Mais detalhes sobre o problema
são informados na seção \ref{subsec:bottle}. A suspeita é que de alguma forma o
\textit{garbage collector} ficou impedido de coletar os \textit{sockets}
antigos, possivelmente devido a maneira de manter uma lista de \textit{sockets}
em uma tabela (uma referência, portanto) a qual não deve estar sendo
corretamente limpa para desreferenciar os \textit{sockets} antigos, para que
possam finalmente ser coletados e ter a memória liberada.

O mesmo cliente foi usado em todos os testes. A implementação do cliente e do
servidor é resistente a desconexão da outra ponta e pode tratar da reconexão
quando necessário. O servidor tem o tamanho do \textit{pool} configurável por
linha de comando, no \textit{start} do processo, e quando configurado para
\textit{pool} de tamanho 0 ou menor atua sem persistência de conexão, forçando o
fechamento após atender cada requisição.

\begin{lstlisting}[label={commandline},language=C,caption=Linha de comando]
    $ ./rpc\_server.lua
    Usage: ./rpc\_server.lua <interface\_file> [server\_port1] [server\_port2] [pool\_size]
\end{lstlisting}

\subsection{Gargalos identificados}\label{subsec:bottle}

Na configuração de teste que determina o uso de mais clientes do que o
\textit{pool} de conexões comporta, foi possível observar um comportamento que
evitou a execução da bateria de testes até o final. Na implementação atual do
\textit{servant}, que é a parte da biblioteca \textit{luarpc} que instancia
um servidor, deve existir algum erro de programação ainda não identificado que
faz com que a memória do servidor cresça rapidamente, impedindo a execução da
bateria até o final.

Aparentemente não está sendo liberada a memória após o
fechamento e descarte dos \textit{sockets} antigos. Talvez a manipulação da
tabela que memoriza a lista de clientes não esteja liberando corretamente as
entradas antigas para que o \textit{garbage collector} possa de fato fazer a
limpeza das entradas descartadas. Esta tabela que memoriza as conexões dos
clientes dentro do intervalo definido para o \textit{pool} de conexões funciona
como uma lista circular limitada, na qual o limite de seu tamanho é o tamanho do
\textit{pool} e ao atingir o limite, as entradas excedentes (e mais antigas) são
descartadas logo após uma chamada \textit{socket:close()} na conexão em vias de
ser descartada.

O problema fica mais evidente quando o servidor é configurado para não persistir
conexão e sempre desconectar o cliente assim que o pedido for atendido. Isto dá
a entender que o ciclo completo e repetido nas listas circulares de conexões
consome de alguma forma bastante memória, a qual não é reclamada em tempo pelo
coletor de lixo.

Outro gargalo interessante foi identificado no laço principal de execução do
servidor no que diz respeito a configuração de \textit{socket:settimeout()} nos
\textit{sockets} para as \textit{syscalls} \textit{socket:accept()},
\textit{socket:select()} e \textit{socket:receive()}. No laço principal do
servidor são feitas chamadas de \textit{socket:accept()} a cada iteração para
aceitar novos clientes, bem como são feitas chamadas \textit{socket:select()}
para determinar o conjuto de \textit{sockets} que está pronto para ser consumido
sem travar. A primeira versão do servidor implementada na biblioteca
\textit{luarpc} fazia as chamadas mencionadas a cada iteração do laço principal
e tinha um \textit{timeout} configurado de 100ms. O tempo de 100ms pode parecer
pouco, mas quando somado a cada iteração do laço principal, ele tem um efeito
muito grande na performance geral do servidor. Como comparação de desempenho,
vale notar que usando valores baixos de \textit{timeout} o servidor conseguia
atender até 4 requisições por segundo. Na versão final, sem \textit{timeout}
configurado (ou seja, sem bloqueio) a capacidade de atendimento do servidor
passou para 5000 requisições por segundo. A principal mudança foi fazer um
\textit{select} nos servidores antes do chamar \textit{accept}, assim a chamada
de accept só será feita se já houver algum cliente interessado em abrir conexão
com o servidor, caso contrário o servidor nem precisa perder tempo fazendo a
chamada de \textit{accept}. Este \textit{select} a mais e o uso de
\textit{timeout} zero para todas as chamadas de sistema fizeram com que o
servidor ficasse bem mais interessante do ponto de vista da performance,
mantendo a estabilidade. Para as etapas de envio e consumo de dados ainda existe
um \textit{timeout} grande configurado, de 10 segundos, para permitir interação
humana em console de depuração (\textit{telnet}).

\section{Melhorias futuras}\label{sec:future}

Para ficar mais idiomática a implementação em Lua, seria interessante
substituir no código o trecho que trata de forma mais tradicional de listas
circulares por algo mais podereso fornecido pela linguagem Lua. A proposta é
alterar o tratamento de \textit{pool} utilizando uma
\textit{metatable}\cite{metat} que no momento da inserção de um novo
\textit{socket} de cliente na tabela de clientes de um servidor poderia avaliar
se o limite de conexões foi atingido e poderia liberar as conexões mais
antigas. A implementação atual tem exatamente o mesmo efeito, mas não usa
totalmente o idioma da linguagem Lua para tanto. A sugestão é utilizar o
\textit{metamethod} \textit{\_\_newindex} para tratar novos índices na tabela que
lista os clientes de um servidor.

\begin{lstlisting}[label={connpool},language=C,caption=Connection Pool]
em C \textit{PPH} em $O(n^2)$ com \textit{array}]
-- Pool size limit.
if #servant.client_list > servant.pool_size then
    while #servant.client_list > servant.pool_size do
        old_client = table.remove(servant.client_list, 1)
        old_client:close()
    end
end
\end{lstlisting}

\renewcommand{\arraystretch}{2}
\begin{table}
\begin{center}
{\footnotesize \begin{tabular}{p{2.5cm} p{2.5cm} p{2.5cm} p{2.5cm} p{2.5cm}}
\hline
\multicolumn{5}{c}{Comparativo de sistemas de arquivos distribuídos} \\ \hline
~ & Tahoe & Ivy & Coda & Ceph \\ \hline
Modelo de comunicação & \textit{peer-to-peer} & \textit{peer-to-peer} & cliente-servidor & cliente-servidor \\
Escalabilidade & média & alta & alta & alta \\
Replicação e redundância & rebalanceamento manual & automática & automática pelo cliente & automática no servidor \\
Concorrência e integridade & consenso e criptografia & perda silenciosa & garantida por callbacks & garantida por sincronia \\
Identificação e resolução de conflitos & não trata & manual com ferramentas & exposição de versões & conflitos inexistentes \\
Detecção e correção de erros & \textit{erasure coding} & \textit{merkle trees} & não possui & versão mais recente \\
Semãntica de consistência & \textit{close-to-open} & \textit{close-to-open} & \textit{close-to-open} & \textit{close-to-open} \\
Operação desconectada & não & não & cópia cacheada com \textit{replay} & não \\ 
Migração & re-réplica manual com ferramenta & transparente & transparente & transparente \\
Performance & baixa & média & alta & alta \\
Suporte a redes móveis & não & não & sim & não \\
\hline
\end{tabular}}
\caption{Tabela comparativa de sistemas de arquivos distribuídos}
\label{tab:compare}
\end{center}
\end{table}

\section{Conclusão}\label{sec:conclusion}

oi

% BIB
\bibliographystyle{abnt-puc-rio}
\bibliography{reference}

\end{document}
