% DOC CLASS
\documentclass[11pt]{article}

% ENCODING
\usepackage[utf8]{inputenc}
\usepackage[brazilian]{babel}

% OUTPUT
\usepackage[nottoc]{tocbibind}
\usepackage{hyperref}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage{makeidx}
\usepackage{float}
\usepackage{array}
\usepackage{boxedminipage}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{amsfonts}
\usepackage{setspace}
\usepackage{comment}
\usepackage[toc,xindy]{glossaries}

% SOURCE CODE
\usepackage{listings}
\usepackage{color}
\usepackage{xcolor}
\usepackage{caption}
\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{\colorbox{gray}{\parbox{\textwidth}{#1#2#3}}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white}

% MARGIN
\setlength{\oddsidemargin}{0.5cm} \setlength{\textwidth}{15cm}
\setlength{\topmargin}{-1.5cm} \setlength{\textheight}{22.3cm}%{24.7cm}
\setlength\parindent{0pt} % Removes all indentation from paragraphs
\renewcommand{\labelenumi}{\alph{enumi}.} % Make numbering in the enumerate environment by letter rather than number (e.g. section 6)

% GLOSSARIES
\makeglossaries
\newacronym{rpc}{RPC}{Remote Procedure Calls}

% DOCUMENT
\begin{document}

\title{Disciplina de Sistemas Distrbuídos [INF 2545] \\ Biblioteca RPC -
Trabalho 1}
\author{Rogério Carvalho Schneider}
\date{Abril 2014}
\maketitle

\begin{center}
\begin{tabular}{l r}
Data dos testes: & 14 de Abril de 2014 \\
Professora: & Noemi Rodriguez
\end{tabular}
\end{center}

\begin{abstract}
Relatório da implementação e testes realizados na biblioteca \textit{luarpc}
para a disciplina de Sistemas Distribuídos do Departamento de Informática da PUC-Rio.
A linguagem Lua foi utilizada na implementação da biblioteca.
\end{abstract}

\doublespacing

\section{Introdução}\label{sec:introduction}

Desenvolvemos uma biblioteca para auxílio a chamada remota de
procedimento, \gls{rpc}, com o objetivo de enfrentar e resolver alguns dos problemas
de comunicação de rede em sistemas distribuídos. A programação de servidor e
cliente \gls{rpc} também serviu de exercício na definição, entendimento e
implementação de um protocolo de comunicação.

A biblioteca consiste no arquivo \textit{luarpc.lua}, que depende da
definição de um arquivo de interface, normalmente chamado de
\textit{interface.lua}. A biblioteca deve poder ser reutilizada por diferentes
implementações de servidor e cliente, para tanto, um contrato foi firmado entre
os desenvolvedores (os alunos da disciplina) de maneira a seguir uma \gls{api}
comum a todas as implementações da biblioteca \textit{luarpc}. Da mesma forma,
foi necessário entrar em acordo quanto ao protocolo de comunicação de rede e de
codificação/decodificação de mensagens a ser utilizado. A implementação desta
biblioteca \gls{rpc} segue as linhas gerais definidas no enunciado do trabalho
\cite{trab1}.

A \gls{api} utilizada foi aquela do enunciado do trabalho, com os métodos
\textit{luarpc.createServant}, \textit{luarpc.waitIncoming} e
\textit{luarpc.createProxy} com exatamente o mesmo número e tipo de parâmetros
sugeridos pelo texto original. O protocolo sofreu pequenas alterações,
principalmente no que diz respeito a forma de codificação e decodificação do
conteúdo das mensagens enviadas.

Durante a evolução da definição do protocolo, uma lista de discussão por
\textit{e-mail} for arranjada de forma que as propostas fossem
comentadas pelos participantes do consórcio que patrocinaria o desenvolvimento
da biblioteca. Uma \gls{rfc} foi definida na lista de discussão e após algumas
rodadas de comentários o consórcio chegou a um entendimento quanto
ao protocolo a ser implementado.

\section{Uma biblioteca \gls{rpc}}\label{sec:rpc}

Uma boa especificação de uma biblioteca de auxílio a chamada remota de
procedimento funciona da seguinte maneira: A sua \gls{api} sugerida deve ser
clara e consistente, no sentido de que diferentes implementações possam se
comportar de maneira idêntica quando estiverem se comunicando com recursos
externos. Para clarificar, uma biblioteca deve manter um comportamento
consistente ao interagir com o arquivo de interface e ao receber chamadas de
criação e tratamento de \textit{servant} e de \textit{proxy} para procedimentos remotos.
A biblioteca deve,
portanto, fornecer um conjunto padronizado de métodos de criação e configuração
de servidores e clientes, e deve interpretar de maneira correta um arquivo de
interface escrito seguindo a \gls{api} especificada.

Na prática, a proposta de especificação e implementação consistente de uma
biblioteca \gls{rpc} espera que os usuários/programadores possam intercambiar
seus diferentes servidores e clientes, desde que todos sigam uma mesma definição
de interface. Uma vez de posse da interface, um cliente qualquer pode,
utilizando a biblioteca proposta \textit{luarpc}, fazer requisições a um
servidor qualquer, para tanto basta que ambos cliente e servidor respeitem e
implementem o correto tratamento do arquivo de interface.

\subsection{O protocolo}\label{subsec:proto}

Particularmente, a regra definida para o protocolo e codificação de mensagens
neste trabalho foi a seguinte:

\begin{itemize}
\item
Nomes de métodos chamados pelo cliente são enviados sem delimitadores;
\item
Parâmetros do tipo \textit{char} ou \textit{string} são enviados com delimitadores
\textit{""} envolvendo o texto transmitido;
\item
Parâmetros do tipo \textit{double} são enviados sem transformação.
\item
Parâmetros do tipo \textit{void} são transformados em \textit{nil} e são enviados
com delimitadores \textit{""} envolvendo o texto transmitido. Resulta no envio
de \textit{"nil"};
\end{itemize}

Ao transmitir conteúdo é necessário que ele seja serializado, codificando
conforme o seguinte acordo, no transmissor:

\begin{itemize}
\item
Usar sequência de escape para \textit{\}, transformando em \textit{\\};
\item
Usar sequência de escape para \textit{\n}, transformando em \textit{\\n};
\item
Usar sequência de escape para \textit{"}, transformando em \textit{\"};
\item
O processo inverso, de decodificação, deve ser feito no receptor.
\end{itemize}

Os tipos válidos \textit{char}, \textit{string}, \textit{double} e
\textit{void} tem o seguinte protocolo de
codificação/decodificação:

\begin{itemize}
\item
\textit{char}: restrito a um caracter
codificação no transmissor: envolto em \textit{""}
exemplo: \textit{"a"}
decodificação no receptor: remove \textit{""}
exemplo: \textit{a}
\item
\textit{string}: sem restrição
codificação no transmissor: envolto em \textit{""}
exemplo: \textit{"abc"}
decodificação no receptor: remove \textit{""}
exemplo: \textit{abc}
\item
\textit{double}: apenas números inteiros ou de ponto flutuante
codificação no transmissor: não há
exemplo: \textit{3.1415}
decodificação no receptor: não há
exemplo: \textit{3.1415}
\item
\textit{void}: transformado em nil, envolto em \textit{""}
codificação no transmissor: nil e \textit{""}
exemplo: \textit{"nil"}
decodificação no receptor: remove \textit{""}
exemplo: \textit{nil}
\item
Todos os tipos devem ser enviados em apenas uma chamada de \textit{socket:send}
e recebidos em apenas uma chamada \textit{socket:receive}, desta maneira, o
correto escape de \textit{string} com quebras de linha (\textit{\n}) é muito importante.
\end{itemize}

O papel do receptor é desfazer a codificação aplicada, seguindo a sequência
inversa de passos, de forma a obter valor e tipo originais transmitidos na
mensagem. Uma saída adotada por alguns desenvolvedores para fazer o escape
inverso de \textit{string}, por exemplo, foi o uso de uma chamada
\textit{return} no conteúdo recebido, o que faz com que alguns escapes sejam
decodificados transparentemente, evitando a necessidade de tratar manualmente,
por exemplo, a remoção de delimitadores \textit{""} no início e fim da linha recebida. Da
mesma forma as contra-barras de sequência de escape também são removidas
automaticamente. De forma contrária, como outras implementações sugeriram,
utilizar esse tipo de artifício pode facilitar a vida do programador mas ao mesmo
tempo introduz uma falha de segurança que permite que uma mensagem trocada
entre cliente e servidor, quando decodificada, tenha seu \textit{payload}
executado como código Lua, abrindo uma brecha para execução remota de código não
desejado. Para evitar este problema, foi utilizada a alternativa de tratamento
manual do conteúdo, fazendo uso de técnica de \textit{search and replace} dos
carateres codificados \textit{\"}, \textit{\\n} e delimitadores \textit{""}. As funções
\textit{string.gsub()} e \textit{string.sub(2,-2)} foram utilizadas para
decodificar \textit{\"} em \textit{"}, \textit{\\n} em \textit{\n} e remover os
delimitadores \textit{""}.

Ao perceber um erro no lado do cliente ou do servidor, o protocolo deve enviar
uma mensagem iniciada por "___ERRORPC:" contendo, possivelmente, a causa do
erro. Em alguns casos especiais de erro no modo de uso, a biblioteca deve tentar evitar
o envio da mensagem de erro e deve tentar corrigir o número e tipo de parâmetros chamados no
cliente ou respondidos pelo servidor. Para tanto, a biblioteca utiliza valores default como
alternativa à falta de parâmetros nas chamadas do cliente e nas respostas do
servidor. O objetivo é prover uma construção o mais limpa possível da sequência
de mensagens a trafegar no canal de comunicação de rede, tentando sempre respeitar o
protocolo definido quanto a tipos, quantidade, codificação e sequência de
parâmetros esperados no transporte entre cliente e servidor, ida e volta.

\section{Testes de performance realizados}\label{sec:perf}

Foram executadas baterias de teste segundo a sugestão do enunciado do trabalho.
Para cada configuração de cenário segue abaixo um parecer e algumas informações
adicionais.

Um cliente especial foi criado para a execução dos testes. Este cliente tem
capacidade de medir o tempo que leva para executar uma série de chamadas em
sequência e também consegue medir o quanto consumiu de tráfego de rede para a
série de chamadas. Em todas as baterias foram executadas 10000 (dez mil)
chamadas a cada método. Os métodos chamados no laço de teste também foram
especialmente implementados e escolhidos para terem diferentes comportamentos
quanto ao custo de tráfego de rede (mensagens pequenas, mensagens grandes) e
custo de processamento (tempo de CPU). Também foram realizadas medições isoladas
para determinar qual o custo de tempo imposto pela biblioteca \textit{luarpc} e
qual o custo imposto pela implementação presente no cliente e no servidor.

\paragraph{Tamanho de string muito pequeno e muito grande}

Neste teste foi utilizado o método chamado \textit{min}, que recebe um string e
devolve apenas um double. Este perfil de teste demonstra o impacto do aumento
do tráfego de dados no desempenho da aplicação.

Como resultado otivemos 

    min = {
      resulttype = "double",
      args = {
        {direction = "in", type = "string"},
      },
    },

    foo = {
      resulttype = "double",
      args = {
        {direction = "in", type = "double"},
        {direction = "in", type = "double"},
        {direction = "out", type = "string"},
      },
    },

    oid = {
      resulttype = "void",
      args = {
        {direction = "in", type = "void"},
      },
    },


    men = {
      resulttype = "double",
      args = {
        {direction = "in", type = "double"},
      },
    },

    tbl = {
      resulttype = "double",
      args = {
        {direction = "in", type = "string"},
      },
    },

\subsection{Gargalos identificados}\label{subsec:bottle}

Na configuração de teste que determina o uso de mais clientes do que o
\textit{pool} de conexões comporta, foi possível observar um comportamento que
evitou a execução da bateria de testes até o final. Na implementação atual do
\textit{servant}, que é a parte da biblioteca \textit{luarpc} que instancia
um servidor, deve existir algum erro de programação ainda não identificado que
faz com que a memória do servidor cresça rapidamente, impedindo a execução da
bateria até o final.

Aparentemente não está sendo liberada a memória após o
fechamento e descarte dos \textit{sockets} antigos. Talvez a manipulação da
tabela que memoriza a lista de clientes não esteja liberando corretamente as
entradas antigas para que o \textit{garbage collector} possa de fato fazer a
limpeza das entradas descartadas. Esta tabela que memoriza as conexões dos
clientes dentro do intervalo definido para o \textit{pool} de conexões funciona
como uma lista circular limitada, na qual o limite de seu tamanho é o tamanho do
\textit{pool} e ao atingir o limite, as entradas excedentes (e mais antigas) são
descartadas logo após uma chamada \textit{socket:close} na conexão em vias de
ser descartada.

O problema fica mais evidente quando o servidor é configurado para não persistir
conexão e sempre desconectar o cliente assim que o pedido for atendido. Isto dá
a entender que o ciclo completo e repetido nas listas circulares de conexões
consome de alguma forma bastante memória, a qual não é reclamada em tempo pelo
coletor de lixo.

\section{Melhorias futuras}\label{sec:future}












Diferença de tempo de entre chamadas sem persistência e com persistência de
conexão.

Cliente com loop de chamadas para alguns métodos especiais de teste, com maior
e menor overhead de rede e de encoding.

Servidor com pool de três conexões.
Como se comporta com apenas um cliente?
Como se comporta com três clientes?
Como se comporta com dez clientes?
Como se comporta cada caso com diferentes servidores, o que mantém e o que não
mantém pool de conexões?


 1 cliente - persist
01:46:24
foo took 2 seconds for server 5001 for 10000 runs
oid took 2 seconds for server 5001 for 10000 runs
min took 2 seconds for server 5001 for 10000 runs
min 10KB took 17 seconds for server 5001 for 10000 runs
men took 3 seconds for server 5001 for 10000 runs
tbl took 8 seconds for server 5001 for 10000 runs
foo took 3 seconds for server 5002 for 10000 runs
oid took 2 seconds for server 5002 for 10000 runs
min took 2 seconds for server 5002 for 10000 runs
min 10KB took 20 seconds for server 5002 for 10000 runs
men took 2 seconds for server 5002 for 10000 runs
tbl took 9 seconds for server 5002 for 10000 runs

01:47:39
foo took 2 seconds for server 5001 for 10000 runs
oid took 2 seconds for server 5001 for 10000 runs
min took 2 seconds for server 5001 for 10000 runs
min 10KB took 20 seconds for server 5001 for 10000 runs
men took 2 seconds for server 5001 for 10000 runs
tbl took 8 seconds for server 5001 for 10000 runs
foo took 3 seconds for server 5002 for 10000 runs
oid took 2 seconds for server 5002 for 10000 runs
min took 2 seconds for server 5002 for 10000 runs
min 10KB took 20 seconds for server 5002 for 10000 runs
men took 2 seconds for server 5002 for 10000 runs
tbl took 9 seconds for server 5002 for 10000 runs


00:04:18
foo took 11 seconds for server 5001 for 50000 runs
oid took 7 seconds for server 5001 for 50000 runs
min took 8 seconds for server 5001 for 50000 runs
min 10KB took 110 seconds for server 5001 for 50000 runs
men took 7 seconds for server 5001 for 50000 runs
tbl took 32 seconds for server 5001 for 50000 runs
foo took 10 seconds for server 5002 for 50000 runs
oid took 8 seconds for server 5002 for 50000 runs
min took 9 seconds for server 5002 for 50000 runs
min 10KB took 112 seconds for server 5002 for 50000 runs
men took 8 seconds for server 5002 for 50000 runs
tbl took 40 seconds for server 5002 for 50000 runs

00:44:11
foo took 13 seconds for server 5001 for 50000 runs
oid took 11 seconds for server 5001 for 50000 runs
min took 11 seconds for server 5001 for 50000 runs
min 10KB took 107 seconds for server 5001 for 50000 runs
men took 11 seconds for server 5001 for 50000 runs
tbl took 39 seconds for server 5001 for 50000 runs
foo took 14 seconds for server 5002 for 50000 runs
oid took 10 seconds for server 5002 for 50000 runs
min took 11 seconds for server 5002 for 50000 runs
min 10KB took 106 seconds for server 5002 for 50000 runs
men took 9 seconds for server 5002 for 50000 runs
tbl took 41 seconds for server 5002 for 50000 runs


 3 clientes - persist
01:50:06
foo took 4 seconds for server 5001 for 10000 runs
oid took 3 seconds for server 5001 for 10000 runs
min took 3 seconds for server 5001 for 10000 runs
min 10KB took 22 seconds for server 5001 for 10000 runs
men took 23 seconds for server 5001 for 10000 runs
tbl took 12 seconds for server 5001 for 10000 runs
foo took 10 seconds for server 5002 for 10000 runs
oid took 5 seconds for server 5002 for 10000 runs
min took 5 seconds for server 5002 for 10000 runs
min 10KB took 27 seconds for server 5002 for 10000 runs
men took 18 seconds for server 5002 for 10000 runs
tbl took 19 seconds for server 5002 for 10000 runs

01:50:35
foo took 6 seconds for server 5001 for 10000 runs
oid took 7 seconds for server 5001 for 10000 runs
min took 13 seconds for server 5001 for 10000 runs
min 10KB took 28 seconds for server 5001 for 10000 runs
men took 10 seconds for server 5001 for 10000 runs
tbl took 12 seconds for server 5001 for 10000 runs
foo took 7 seconds for server 5002 for 10000 runs
oid took 9 seconds for server 5002 for 10000 runs
min took 15 seconds for server 5002 for 10000 runs
min 10KB took 31 seconds for server 5002 for 10000 runs
men took 14 seconds for server 5002 for 10000 runs
tbl took 15 seconds for server 5002 for 10000 runs

01:50:36
foo took 7 seconds for server 5001 for 10000 runs
oid took 8 seconds for server 5001 for 10000 runs
min took 18 seconds for server 5001 for 10000 runs
min 10KB took 27 seconds for server 5001 for 10000 runs
men took 9 seconds for server 5001 for 10000 runs
tbl took 11 seconds for server 5001 for 10000 runs
foo took 8 seconds for server 5002 for 10000 runs
oid took 15 seconds for server 5002 for 10000 runs
min took 17 seconds for server 5002 for 10000 runs
min 10KB took 31 seconds for server 5002 for 10000 runs
men took 5 seconds for server 5002 for 10000 runs
tbl took 14 seconds for server 5002 for 10000 runs

01:54:44
foo took 7 seconds for server 5001 for 10000 runs
oid took 10 seconds for server 5001 for 10000 runs
min took 21 seconds for server 5001 for 10000 runs
min 10KB took 31 seconds for server 5001 for 10000 runs
men took 10 seconds for server 5001 for 10000 runs
tbl took 16 seconds for server 5001 for 10000 runs
foo took 9 seconds for server 5002 for 10000 runs
oid took 17 seconds for server 5002 for 10000 runs
min took 18 seconds for server 5002 for 10000 runs
min 10KB took 33 seconds for server 5002 for 10000 runs
men took 6 seconds for server 5002 for 10000 runs
tbl took 12 seconds for server 5002 for 10000 runs

01:54:45
foo took 7 seconds for server 5001 for 10000 runs
oid took 7 seconds for server 5001 for 10000 runs
min took 16 seconds for server 5001 for 10000 runs
min 10KB took 30 seconds for server 5001 for 10000 runs
men took 13 seconds for server 5001 for 10000 runs
tbl took 15 seconds for server 5001 for 10000 runs
foo took 9 seconds for server 5002 for 10000 runs
oid took 7 seconds for server 5002 for 10000 runs
min took 16 seconds for server 5002 for 10000 runs
min 10KB took 29 seconds for server 5002 for 10000 runs
men took 15 seconds for server 5002 for 10000 runs
tbl took 16 seconds for server 5002 for 10000 runs

01:54:46
foo took 4 seconds for server 5001 for 10000 runs
oid took 5 seconds for server 5001 for 10000 runs
min took 4 seconds for server 5001 for 10000 runs
min 10KB took 26 seconds for server 5001 for 10000 runs
men took 25 seconds for server 5001 for 10000 runs
tbl took 17 seconds for server 5001 for 10000 runs
foo took 11 seconds for server 5002 for 10000 runs
oid took 7 seconds for server 5002 for 10000 runs
min took 6 seconds for server 5002 for 10000 runs
min 10KB took 25 seconds for server 5002 for 10000 runs
men took 16 seconds for server 5002 for 10000 runs
tbl took 20 seconds for server 5002 for 10000 runs


00:30:35
foo took 16 seconds for server 5001 for 50000 runs
oid took 16 seconds for server 5001 for 50000 runs
min took 15 seconds for server 5001 for 50000 runs
min 10KB took 88 seconds for server 5001 for 50000 runs
men took 98 seconds for server 5001 for 50000 runs
tbl took 82 seconds for server 5001 for 50000 runs
foo took 43 seconds for server 5002 for 50000 runs
oid took 45 seconds for server 5002 for 50000 runs
min took 19 seconds for server 5002 for 50000 runs
min 10KB took 101 seconds for server 5002 for 50000 runs
men took 17 seconds for server 5002 for 50000 runs
tbl took 79 seconds for server 5002 for 50000 runs

00:30:35
foo took 30 seconds for server 5001 for 50000 runs
oid took 38 seconds for server 5001 for 50000 runs
min took 72 seconds for server 5001 for 50000 runs
min 10KB took 147 seconds for server 5001 for 50000 runs
men took 39 seconds for server 5001 for 50000 runs
tbl took 59 seconds for server 5001 for 50000 runs
foo took 38 seconds for server 5002 for 50000 runs
oid took 91 seconds for server 5002 for 50000 runs
min took 39 seconds for server 5002 for 50000 runs
min 10KB took 140 seconds for server 5002 for 50000 runs
men took 33 seconds for server 5002 for 50000 runs
tbl took 59 seconds for server 5002 for 50000 runs

00:30:34
foo took 31 seconds for server 5001 for 50000 runs
oid took 43 seconds for server 5001 for 50000 runs
min took 73 seconds for server 5001 for 50000 runs
min 10KB took 150 seconds for server 5001 for 50000 runs
men took 35 seconds for server 5001 for 50000 runs
tbl took 65 seconds for server 5001 for 50000 runs
foo took 57 seconds for server 5002 for 50000 runs
oid took 75 seconds for server 5002 for 50000 runs
min took 57 seconds for server 5002 for 50000 runs
min 10KB took 135 seconds for server 5002 for 50000 runs
men took 23 seconds for server 5002 for 50000 runs
tbl took 60 seconds for server 5002 for 50000 runs


 10 clientes - persist
02:04:46
foo took 24 seconds for server 5001 for 10000 runs
oid took 21 seconds for server 5001 for 10000 runs
min took 45 seconds for server 5001 for 10000 runs
min 10KB took 113 seconds for server 5001 for 10000 runs
men took 30 seconds for server 5001 for 10000 runs
tbl took 57 seconds for server 5001 for 10000 runs
foo took 26 seconds for server 5002 for 10000 runs
oid took 25 seconds for server 5002 for 10000 runs
min took 48 seconds for server 5002 for 10000 runs
min 10KB took 110 seconds for server 5002 for 10000 runs
men took 33 seconds for server 5002 for 10000 runs
tbl took 56 seconds for server 5002 for 10000 runs


 Table apenas
tblonly serialize took 4 seconds for 10000 runs
tblonly deserialize took 2 seconds for 10000 runs
tblonly serialize/deserialize took 6 seconds for 10000 runs

tblonly serialize took 22 seconds for 50000 runs
tblonly deserialize took 7 seconds for 50000 runs
tblonly serialize/deserialize took 32 seconds for 50000 runs


 1 cliente - close connection
02:23:45
foo took 4 seconds for server 5001 for 10000 runs
oid took 4 seconds for server 5001 for 10000 runs
min took 4 seconds for server 5001 for 10000 runs
min 10KB took 21 seconds for server 5001 for 10000 runs
men took 4 seconds for server 5001 for 10000 runs
tbl took 10 seconds for server 5001 for 10000 runs
foo took 5 seconds for server 5002 for 10000 runs
oid took 4 seconds for server 5002 for 10000 runs
min took 4 seconds for server 5002 for 10000 runs
min 10KB took 21 seconds for server 5002 for 10000 runs
men took 4 seconds for server 5002 for 10000 runs
tbl took 11 seconds for server 5002 for 10000 runs


 3 clientes - close connection
02:33:17
foo took 5 seconds for server 5001 for 10000 runs
oid took 7 seconds for server 5001 for 10000 runs
min took 8 seconds for server 5001 for 10000 runs
min 10KB took 32 seconds for server 5001 for 10000 runs
men took 10 seconds for server 5001 for 10000 runs
tbl took 17 seconds for server 5001 for 10000 runs
foo took 10 seconds for server 5002 for 10000 runs
oid took 9 seconds for server 5002 for 10000 runs
min took 8 seconds for server 5002 for 10000 runs
min 10KB took 35 seconds for server 5002 for 10000 runs
men took 6 seconds for server 5002 for 10000 runs
tbl took 19 seconds for server 5002 for 10000 runs

% BIB
\bibliographystyle{abnt-puc-rio}
\bibliography{reference}

\end{document}
